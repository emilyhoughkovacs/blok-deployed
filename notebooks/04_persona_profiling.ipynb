{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persona Profiling: From Cluster Centroids to Behavioral Personas\n",
    "\n",
    "**Objective**: Transform K-means cluster centroids into interpretable behavioral personas with natural language descriptions.\n",
    "\n",
    "## Workflow\n",
    "1. Load clustering outputs and compute centroids in original (unscaled) space\n",
    "2. Generate statistical profiles comparing each cluster to the population\n",
    "3. Map statistics to descriptive behavioral labels\n",
    "4. Create natural language persona descriptions\n",
    "5. Export personas for agent instantiation (Phase 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Style settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path('../data/processed')\n",
    "OUTPUT_DIR = Path('../data/processed')\n",
    "FIG_DIR = Path('./outputs/04_persona_profiling')\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR.resolve()}\")\n",
    "print(f\"Figure directory: {FIG_DIR.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Clustering Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cluster assignments\n",
    "clusters = pd.read_csv(DATA_DIR / 'customer_clusters.csv', index_col='customer_unique_id')\n",
    "\n",
    "# Load raw (non-log) features\n",
    "features_raw = pd.read_csv(DATA_DIR / 'customer_features_raw.csv', index_col='customer_unique_id')\n",
    "\n",
    "# Load transformed (log) features\n",
    "features_transformed = pd.read_csv(DATA_DIR / 'customer_features_transformed.csv', index_col='customer_unique_id')\n",
    "\n",
    "# Load metadata\n",
    "with open(DATA_DIR / 'feature_metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "print(f\"Cluster assignments: {clusters.shape}\")\n",
    "print(f\"Raw features: {features_raw.shape}\")\n",
    "print(f\"Transformed features: {features_transformed.shape}\")\n",
    "print(f\"\\nNumber of clusters: {metadata['clustering']['n_clusters']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge cluster labels with raw features\n",
    "df = features_raw.join(clusters)\n",
    "\n",
    "print(f\"Combined dataframe: {df.shape}\")\n",
    "print(f\"\\nCluster distribution:\")\n",
    "cluster_counts = df['cluster'].value_counts().sort_index()\n",
    "for cluster_id, count in cluster_counts.items():\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"  Cluster {cluster_id}: {count:,} customers ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute Cluster Centroids (Original Scale)\n",
    "\n",
    "The clustering was performed on log-transformed, standardized features. To interpret the clusters, we need centroids in the original scale (e.g., R$ for monetary values, counts for frequency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature groups\n",
    "RAW_FEATURES = [\n",
    "    'frequency',\n",
    "    'monetary_total',\n",
    "    'monetary_avg_item',\n",
    "    'avg_items_per_order',\n",
    "    'avg_installments',\n",
    "    'pct_credit_card',\n",
    "    'category_diversity',\n",
    "    'is_positive_reviewer',\n",
    "    'is_weekend_shopper'\n",
    "]\n",
    "\n",
    "# Compute cluster means in original scale\n",
    "cluster_centroids = df.groupby('cluster')[RAW_FEATURES].mean()\n",
    "\n",
    "print(\"Cluster Centroids (Original Scale):\")\n",
    "cluster_centroids.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute population statistics for comparison\n",
    "population_stats = df[RAW_FEATURES].agg(['mean', 'median', 'std'])\n",
    "\n",
    "print(\"Population Statistics:\")\n",
    "population_stats.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute z-scores: how many std deviations each cluster is from the population mean\n",
    "# This helps identify which features distinguish each cluster\n",
    "pop_mean = population_stats.loc['mean']\n",
    "pop_std = population_stats.loc['std']\n",
    "\n",
    "cluster_zscores = (cluster_centroids - pop_mean) / pop_std\n",
    "\n",
    "print(\"Cluster Z-Scores (deviation from population mean in std units):\")\n",
    "cluster_zscores.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Cluster Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of z-scores\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "sns.heatmap(\n",
    "    cluster_zscores.T, \n",
    "    annot=True, \n",
    "    cmap='RdBu_r', \n",
    "    center=0, \n",
    "    fmt='.2f',\n",
    "    linewidths=0.5, \n",
    "    ax=ax, \n",
    "    cbar_kws={'label': 'Z-Score (std from population mean)'}\n",
    ")\n",
    "ax.set_title('Cluster Profiles: Deviation from Population Mean', fontsize=14)\n",
    "ax.set_xlabel('Cluster', fontsize=12)\n",
    "ax.set_ylabel('Feature', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / 'cluster_zscore_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Saved: {FIG_DIR / 'cluster_zscore_heatmap.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radar chart for each cluster\n",
    "from math import pi\n",
    "\n",
    "def create_radar_chart(cluster_zscores, cluster_id, ax):\n",
    "    \"\"\"Create a radar chart for a single cluster.\"\"\"\n",
    "    categories = list(cluster_zscores.columns)\n",
    "    n_cats = len(categories)\n",
    "    \n",
    "    # Compute angles for each feature\n",
    "    angles = [n / float(n_cats) * 2 * pi for n in range(n_cats)]\n",
    "    angles += angles[:1]  # Complete the loop\n",
    "    \n",
    "    # Get values for this cluster\n",
    "    values = cluster_zscores.loc[cluster_id].values.tolist()\n",
    "    values += values[:1]  # Complete the loop\n",
    "    \n",
    "    # Plot\n",
    "    ax.plot(angles, values, 'o-', linewidth=2, label=f'Cluster {cluster_id}')\n",
    "    ax.fill(angles, values, alpha=0.25)\n",
    "    \n",
    "    # Set labels\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(categories, size=8)\n",
    "    ax.set_title(f'Cluster {cluster_id}', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Set y-axis limits\n",
    "    ax.set_ylim(-2.5, 2.5)\n",
    "\n",
    "# Create radar charts for all clusters\n",
    "n_clusters = len(cluster_zscores)\n",
    "n_cols = 4\n",
    "n_rows = (n_clusters + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 4*n_rows), \n",
    "                         subplot_kw=dict(polar=True))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, cluster_id in enumerate(cluster_zscores.index):\n",
    "    create_radar_chart(cluster_zscores, cluster_id, axes[i])\n",
    "\n",
    "# Hide unused subplots\n",
    "for j in range(i+1, len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "plt.suptitle('Cluster Behavioral Profiles (Z-Scores)', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / 'cluster_radar_charts.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Saved: {FIG_DIR / 'cluster_radar_charts.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Statistical Profile → Descriptive Labels\n",
    "\n",
    "Map quantitative centroid values to human-readable behavioral descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_feature(feature_name: str, value: float, zscore: float, pop_stats: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Generate a descriptive label for a feature value based on its z-score.\n",
    "    \n",
    "    Args:\n",
    "        feature_name: Name of the feature\n",
    "        value: Raw feature value (cluster centroid)\n",
    "        zscore: Z-score relative to population\n",
    "        pop_stats: Population statistics DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        Human-readable description\n",
    "    \"\"\"\n",
    "    pop_mean = pop_stats.loc['mean', feature_name]\n",
    "    \n",
    "    # Determine magnitude\n",
    "    if abs(zscore) < 0.5:\n",
    "        magnitude = \"average\"\n",
    "    elif abs(zscore) < 1.0:\n",
    "        magnitude = \"slightly \" + (\"above\" if zscore > 0 else \"below\") + \" average\"\n",
    "    elif abs(zscore) < 1.5:\n",
    "        magnitude = \"moderately \" + (\"high\" if zscore > 0 else \"low\")\n",
    "    elif abs(zscore) < 2.0:\n",
    "        magnitude = \"high\" if zscore > 0 else \"low\"\n",
    "    else:\n",
    "        magnitude = \"very \" + (\"high\" if zscore > 0 else \"low\")\n",
    "    \n",
    "    # Feature-specific descriptions\n",
    "    descriptions = {\n",
    "        'frequency': {\n",
    "            'metric': f\"{value:.1f} orders\",\n",
    "            'behavior': \"repeat buyer\" if value > 1.5 else \"one-time buyer\" if value < 1.1 else \"occasional repeat buyer\"\n",
    "        },\n",
    "        'monetary_total': {\n",
    "            'metric': f\"R${value:.0f} lifetime\",\n",
    "            'behavior': \"high-value\" if zscore > 1 else \"budget-conscious\" if zscore < -1 else \"moderate spender\"\n",
    "        },\n",
    "        'monetary_avg_item': {\n",
    "            'metric': f\"R${value:.0f}/item\",\n",
    "            'behavior': \"premium buyer\" if zscore > 1 else \"bargain hunter\" if zscore < -1 else \"mid-range buyer\"\n",
    "        },\n",
    "        'avg_items_per_order': {\n",
    "            'metric': f\"{value:.1f} items/order\",\n",
    "            'behavior': \"bulk buyer\" if zscore > 1 else \"single-item buyer\" if zscore < -0.5 else \"typical basket\"\n",
    "        },\n",
    "        'avg_installments': {\n",
    "            'metric': f\"{value:.1f} installments\",\n",
    "            'behavior': \"heavy financing\" if value > 5 else \"cash/single payment\" if value < 1.5 else \"moderate financing\"\n",
    "        },\n",
    "        'pct_credit_card': {\n",
    "            'metric': f\"{value*100:.0f}% credit card\",\n",
    "            'behavior': \"credit card exclusive\" if value > 0.95 else \"cash/boleto preference\" if value < 0.3 else \"mixed payment\"\n",
    "        },\n",
    "        'category_diversity': {\n",
    "            'metric': f\"{value:.1f} categories\",\n",
    "            'behavior': \"category explorer\" if value > 1.5 else \"category focused\" if value <= 1 else \"slight explorer\"\n",
    "        },\n",
    "        'is_positive_reviewer': {\n",
    "            'metric': f\"{value*100:.0f}% positive\",\n",
    "            'behavior': \"satisfied customer\" if value > 0.85 else \"critical reviewer\" if value < 0.5 else \"mixed satisfaction\"\n",
    "        },\n",
    "        'is_weekend_shopper': {\n",
    "            'metric': f\"{value*100:.0f}% weekend\",\n",
    "            'behavior': \"weekend shopper\" if value > 0.5 else \"weekday shopper\" if value < 0.15 else \"any-day shopper\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    desc = descriptions.get(feature_name, {'metric': str(value), 'behavior': magnitude})\n",
    "    return f\"{desc['metric']} ({desc['behavior']})\"\n",
    "\n",
    "\n",
    "# Test the function\n",
    "print(\"Example descriptions for Cluster 0:\")\n",
    "for feature in RAW_FEATURES:\n",
    "    val = cluster_centroids.loc[0, feature]\n",
    "    z = cluster_zscores.loc[0, feature]\n",
    "    print(f\"  {feature}: {describe_feature(feature, val, z, population_stats)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_distinguishing_features(cluster_id: int, zscores: pd.DataFrame, threshold: float = 0.75) -> dict:\n",
    "    \"\"\"\n",
    "    Identify the features that most distinguish a cluster from the population.\n",
    "    \n",
    "    Args:\n",
    "        cluster_id: Cluster to analyze\n",
    "        zscores: DataFrame of z-scores\n",
    "        threshold: Minimum |z-score| to be considered distinguishing\n",
    "    \n",
    "    Returns:\n",
    "        Dict with 'high' and 'low' feature lists\n",
    "    \"\"\"\n",
    "    cluster_z = zscores.loc[cluster_id]\n",
    "    \n",
    "    high_features = cluster_z[cluster_z > threshold].sort_values(ascending=False)\n",
    "    low_features = cluster_z[cluster_z < -threshold].sort_values(ascending=True)\n",
    "    \n",
    "    return {\n",
    "        'high': list(high_features.index),\n",
    "        'low': list(low_features.index),\n",
    "        'high_zscores': high_features.to_dict(),\n",
    "        'low_zscores': low_features.to_dict()\n",
    "    }\n",
    "\n",
    "\n",
    "# Identify distinguishing features for each cluster\n",
    "distinguishing_features = {}\n",
    "for cluster_id in cluster_zscores.index:\n",
    "    distinguishing_features[cluster_id] = identify_distinguishing_features(cluster_id, cluster_zscores)\n",
    "    print(f\"\\nCluster {cluster_id}:\")\n",
    "    print(f\"  High: {distinguishing_features[cluster_id]['high']}\")\n",
    "    print(f\"  Low: {distinguishing_features[cluster_id]['low']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Cluster Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cluster_summary(cluster_id: int, \n",
    "                             centroids: pd.DataFrame, \n",
    "                             zscores: pd.DataFrame, \n",
    "                             pop_stats: pd.DataFrame,\n",
    "                             cluster_sizes: pd.Series) -> dict:\n",
    "    \"\"\"\n",
    "    Generate a complete summary for a cluster.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with cluster statistics and descriptions\n",
    "    \"\"\"\n",
    "    centroid = centroids.loc[cluster_id]\n",
    "    zscore = zscores.loc[cluster_id]\n",
    "    size = cluster_sizes[cluster_id]\n",
    "    pct = size / cluster_sizes.sum() * 100\n",
    "    \n",
    "    # Feature descriptions\n",
    "    feature_descriptions = {}\n",
    "    for feature in RAW_FEATURES:\n",
    "        feature_descriptions[feature] = {\n",
    "            'value': centroid[feature],\n",
    "            'zscore': zscore[feature],\n",
    "            'description': describe_feature(feature, centroid[feature], zscore[feature], pop_stats)\n",
    "        }\n",
    "    \n",
    "    # Distinguishing features\n",
    "    distinguishing = identify_distinguishing_features(cluster_id, zscores)\n",
    "    \n",
    "    return {\n",
    "        'cluster_id': cluster_id,\n",
    "        'size': int(size),\n",
    "        'percentage': pct,\n",
    "        'features': feature_descriptions,\n",
    "        'distinguishing_high': distinguishing['high'],\n",
    "        'distinguishing_low': distinguishing['low']\n",
    "    }\n",
    "\n",
    "\n",
    "# Generate summaries for all clusters\n",
    "cluster_summaries = {}\n",
    "for cluster_id in cluster_zscores.index:\n",
    "    cluster_summaries[cluster_id] = generate_cluster_summary(\n",
    "        cluster_id, cluster_centroids, cluster_zscores, population_stats, cluster_counts\n",
    "    )\n",
    "\n",
    "# Display summary for cluster 0 as example\n",
    "print(\"Example: Cluster 0 Summary\")\n",
    "print(\"=\" * 50)\n",
    "summary = cluster_summaries[0]\n",
    "print(f\"Size: {summary['size']:,} customers ({summary['percentage']:.1f}%)\")\n",
    "print(f\"\\nDistinguishing HIGH features: {summary['distinguishing_high']}\")\n",
    "print(f\"Distinguishing LOW features: {summary['distinguishing_low']}\")\n",
    "print(f\"\\nFeature breakdown:\")\n",
    "for feature, desc in summary['features'].items():\n",
    "    print(f\"  {feature}: {desc['description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary table for all clusters\n",
    "summary_table = pd.DataFrame({\n",
    "    'Cluster': range(len(cluster_summaries)),\n",
    "    'Size': [cluster_summaries[i]['size'] for i in range(len(cluster_summaries))],\n",
    "    'Pct': [f\"{cluster_summaries[i]['percentage']:.1f}%\" for i in range(len(cluster_summaries))],\n",
    "    'Distinguishing High': [', '.join(cluster_summaries[i]['distinguishing_high'][:3]) for i in range(len(cluster_summaries))],\n",
    "    'Distinguishing Low': [', '.join(cluster_summaries[i]['distinguishing_low'][:3]) for i in range(len(cluster_summaries))]\n",
    "})\n",
    "\n",
    "print(\"Cluster Summary Table:\")\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Descriptive Labels → NLP Personas\n",
    "\n",
    "Transform statistical profiles into natural language persona descriptions suitable for LLM agent instantiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_decision_heuristics(summary: dict) -> list:\n",
    "    \"\"\"\n",
    "    Infer behavioral decision heuristics from cluster statistics.\n",
    "    These are hypotheses about WHY customers behave the way they do.\n",
    "    \"\"\"\n",
    "    heuristics = []\n",
    "    features = summary['features']\n",
    "    \n",
    "    # Payment behavior heuristics\n",
    "    installments = features['avg_installments']['value']\n",
    "    cc_pct = features['pct_credit_card']['value']\n",
    "    \n",
    "    if installments > 5:\n",
    "        heuristics.append(\"I evaluate purchases by monthly payment size, not total cost. Spreading payments makes expensive items accessible.\")\n",
    "    elif installments < 1.5 and cc_pct < 0.3:\n",
    "        heuristics.append(\"I avoid debt and prefer to pay upfront. If I can't afford it now, I'll wait or find an alternative.\")\n",
    "    elif installments < 2 and cc_pct > 0.9:\n",
    "        heuristics.append(\"I use credit cards for convenience and rewards, but pay off balances quickly.\")\n",
    "    \n",
    "    # Spending behavior heuristics\n",
    "    monetary_z = features['monetary_total']['zscore']\n",
    "    avg_item_z = features['monetary_avg_item']['zscore']\n",
    "    \n",
    "    if monetary_z > 1 and avg_item_z > 1:\n",
    "        heuristics.append(\"Quality matters more than price. I'm willing to pay premium for better products.\")\n",
    "    elif monetary_z < -0.5 and avg_item_z < -0.5:\n",
    "        heuristics.append(\"I'm price-conscious and actively seek deals. I compare prices before purchasing.\")\n",
    "    elif avg_item_z > 1 and features['avg_items_per_order']['zscore'] < 0:\n",
    "        heuristics.append(\"I make deliberate, considered purchases. Each buy is a decision, not an impulse.\")\n",
    "    \n",
    "    # Review behavior heuristics\n",
    "    positive_pct = features['is_positive_reviewer']['value']\n",
    "    \n",
    "    if positive_pct > 0.9:\n",
    "        heuristics.append(\"I'm generally satisfied with my purchases and appreciate when things work as expected.\")\n",
    "    elif positive_pct < 0.5:\n",
    "        heuristics.append(\"I have high standards and will voice concerns when products don't meet expectations.\")\n",
    "    elif 0.5 <= positive_pct <= 0.7:\n",
    "        heuristics.append(\"I'm discerning but fair. I'll praise good experiences and critique poor ones.\")\n",
    "    \n",
    "    # Shopping pattern heuristics\n",
    "    weekend_pct = features['is_weekend_shopper']['value']\n",
    "    frequency = features['frequency']['value']\n",
    "    \n",
    "    if weekend_pct > 0.5:\n",
    "        heuristics.append(\"I shop during leisure time, often browsing before buying.\")\n",
    "    elif weekend_pct < 0.15:\n",
    "        heuristics.append(\"I shop with purpose during the workweek, often for specific needs.\")\n",
    "    \n",
    "    if frequency > 1.5:\n",
    "        heuristics.append(\"I'm comfortable with online shopping and return when I have a good experience.\")\n",
    "    elif frequency < 1.05:\n",
    "        heuristics.append(\"Online shopping is transactional for me—I buy what I need and move on.\")\n",
    "    \n",
    "    # Category behavior\n",
    "    cat_diversity = features['category_diversity']['value']\n",
    "    if cat_diversity > 1.5:\n",
    "        heuristics.append(\"I treat this marketplace as a one-stop shop for various needs.\")\n",
    "    elif cat_diversity <= 1:\n",
    "        heuristics.append(\"I come here for specific product types—I know what I'm looking for.\")\n",
    "    \n",
    "    return heuristics\n",
    "\n",
    "\n",
    "# Test on cluster 0\n",
    "print(\"Inferred heuristics for Cluster 0:\")\n",
    "for h in infer_decision_heuristics(cluster_summaries[0]):\n",
    "    print(f\"  • {h}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_persona_name(summary: dict) -> str:\n",
    "    \"\"\"\n",
    "    Generate a descriptive persona name based on distinguishing features.\n",
    "    \"\"\"\n",
    "    features = summary['features']\n",
    "    high = summary['distinguishing_high']\n",
    "    low = summary['distinguishing_low']\n",
    "    \n",
    "    # Name components based on strongest signals\n",
    "    name_parts = []\n",
    "    \n",
    "    # Spending level\n",
    "    monetary_z = features['monetary_total']['zscore']\n",
    "    if monetary_z > 1.5:\n",
    "        name_parts.append(\"Premium\")\n",
    "    elif monetary_z > 0.75:\n",
    "        name_parts.append(\"High-Value\")\n",
    "    elif monetary_z < -0.75:\n",
    "        name_parts.append(\"Budget\")\n",
    "    \n",
    "    # Payment style\n",
    "    if 'avg_installments' in high:\n",
    "        name_parts.append(\"Financing\")\n",
    "    elif 'pct_credit_card' in low:\n",
    "        name_parts.append(\"Cash\")\n",
    "    \n",
    "    # Review tendency\n",
    "    if 'is_positive_reviewer' in high:\n",
    "        name_parts.append(\"Satisfied\")\n",
    "    elif 'is_positive_reviewer' in low:\n",
    "        name_parts.append(\"Critical\")\n",
    "    \n",
    "    # Shopping pattern\n",
    "    if 'is_weekend_shopper' in high:\n",
    "        name_parts.append(\"Weekend\")\n",
    "    elif 'frequency' in high:\n",
    "        name_parts.append(\"Loyal\")\n",
    "    \n",
    "    # Basket behavior\n",
    "    if 'avg_items_per_order' in high:\n",
    "        name_parts.append(\"Bulk\")\n",
    "    if 'category_diversity' in high:\n",
    "        name_parts.append(\"Explorer\")\n",
    "    \n",
    "    # Fallback\n",
    "    if not name_parts:\n",
    "        name_parts.append(\"Mainstream\")\n",
    "    \n",
    "    # Add archetype suffix\n",
    "    suffixes = [\"Shopper\", \"Buyer\", \"Customer\"]\n",
    "    \n",
    "    return \" \".join(name_parts[:2]) + \" \" + suffixes[summary['cluster_id'] % len(suffixes)]\n",
    "\n",
    "\n",
    "# Generate names for all clusters\n",
    "print(\"Generated Persona Names:\")\n",
    "for cluster_id, summary in cluster_summaries.items():\n",
    "    name = generate_persona_name(summary)\n",
    "    print(f\"  Cluster {cluster_id}: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_persona_description(summary: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Generate a complete natural language persona description.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing persona name, description, and structured attributes\n",
    "    \"\"\"\n",
    "    cluster_id = summary['cluster_id']\n",
    "    features = summary['features']\n",
    "    \n",
    "    # Generate components\n",
    "    persona_name = generate_persona_name(summary)\n",
    "    heuristics = infer_decision_heuristics(summary)\n",
    "    \n",
    "    # Build behavioral profile section\n",
    "    behavioral_profile = []\n",
    "    \n",
    "    # Frequency & Spending\n",
    "    freq = features['frequency']['value']\n",
    "    monetary = features['monetary_total']['value']\n",
    "    avg_item = features['monetary_avg_item']['value']\n",
    "    \n",
    "    if freq > 1.5:\n",
    "        behavioral_profile.append(f\"Repeat customer with {freq:.1f} orders on average\")\n",
    "    else:\n",
    "        behavioral_profile.append(\"Typically makes a single purchase\")\n",
    "    \n",
    "    behavioral_profile.append(f\"Average lifetime spend of R${monetary:.0f}\")\n",
    "    behavioral_profile.append(f\"Typical item price around R${avg_item:.0f}\")\n",
    "    \n",
    "    # Basket\n",
    "    basket = features['avg_items_per_order']['value']\n",
    "    if basket > 1.5:\n",
    "        behavioral_profile.append(f\"Buys multiple items per order ({basket:.1f} items on average)\")\n",
    "    else:\n",
    "        behavioral_profile.append(\"Usually buys one item per order\")\n",
    "    \n",
    "    # Payment\n",
    "    installments = features['avg_installments']['value']\n",
    "    cc_pct = features['pct_credit_card']['value']\n",
    "    \n",
    "    if cc_pct > 0.9:\n",
    "        payment_desc = \"Almost exclusively uses credit card\"\n",
    "    elif cc_pct < 0.2:\n",
    "        payment_desc = \"Prefers boleto/debit over credit\"\n",
    "    else:\n",
    "        payment_desc = f\"Uses credit card for {cc_pct*100:.0f}% of purchases\"\n",
    "    \n",
    "    if installments > 4:\n",
    "        payment_desc += f\", typically in {installments:.0f} installments\"\n",
    "    elif installments < 1.5:\n",
    "        payment_desc += \", usually paying in full\"\n",
    "    else:\n",
    "        payment_desc += f\", averaging {installments:.1f} installments\"\n",
    "    \n",
    "    behavioral_profile.append(payment_desc)\n",
    "    \n",
    "    # Categories\n",
    "    cat_div = features['category_diversity']['value']\n",
    "    if cat_div > 1.5:\n",
    "        behavioral_profile.append(f\"Explores multiple product categories ({cat_div:.1f} on average)\")\n",
    "    else:\n",
    "        behavioral_profile.append(\"Focused on specific product categories\")\n",
    "    \n",
    "    # Review behavior\n",
    "    positive_pct = features['is_positive_reviewer']['value']\n",
    "    if positive_pct > 0.9:\n",
    "        behavioral_profile.append(\"Highly satisfied—reviews are consistently positive\")\n",
    "    elif positive_pct > 0.7:\n",
    "        behavioral_profile.append(\"Generally satisfied, with occasional concerns\")\n",
    "    elif positive_pct > 0.5:\n",
    "        behavioral_profile.append(\"Mixed satisfaction—reviews reflect both positive and negative experiences\")\n",
    "    else:\n",
    "        behavioral_profile.append(\"Often critical in reviews—holds products to high standards\")\n",
    "    \n",
    "    # Shopping timing\n",
    "    weekend_pct = features['is_weekend_shopper']['value']\n",
    "    if weekend_pct > 0.5:\n",
    "        behavioral_profile.append(\"Shops primarily on weekends\")\n",
    "    elif weekend_pct < 0.15:\n",
    "        behavioral_profile.append(\"Shops primarily on weekdays\")\n",
    "    else:\n",
    "        behavioral_profile.append(\"No strong weekday/weekend preference\")\n",
    "    \n",
    "    # Build the full description\n",
    "    description = f\"\"\"\n",
    "## {persona_name}\n",
    "\n",
    "**Cluster {cluster_id}** | {summary['size']:,} customers ({summary['percentage']:.1f}% of population)\n",
    "\n",
    "### Behavioral Profile\n",
    "{\"; \".join(behavioral_profile)}.\n",
    "\n",
    "### Decision Heuristics\n",
    "{chr(10).join('- ' + h for h in heuristics)}\n",
    "\n",
    "### Key Statistics\n",
    "| Metric | Value | vs. Population |\n",
    "|--------|-------|----------------|\n",
    "| Lifetime Spend | R${monetary:.0f} | {'+' if features['monetary_total']['zscore'] > 0 else ''}{features['monetary_total']['zscore']:.1f}σ |\n",
    "| Avg Item Price | R${avg_item:.0f} | {'+' if features['monetary_avg_item']['zscore'] > 0 else ''}{features['monetary_avg_item']['zscore']:.1f}σ |\n",
    "| Installments | {installments:.1f} | {'+' if features['avg_installments']['zscore'] > 0 else ''}{features['avg_installments']['zscore']:.1f}σ |\n",
    "| Credit Card % | {cc_pct*100:.0f}% | {'+' if features['pct_credit_card']['zscore'] > 0 else ''}{features['pct_credit_card']['zscore']:.1f}σ |\n",
    "| Positive Reviews | {positive_pct*100:.0f}% | {'+' if features['is_positive_reviewer']['zscore'] > 0 else ''}{features['is_positive_reviewer']['zscore']:.1f}σ |\n",
    "\"\"\".strip()\n",
    "    \n",
    "    return {\n",
    "        'cluster_id': cluster_id,\n",
    "        'persona_name': persona_name,\n",
    "        'description_markdown': description,\n",
    "        'behavioral_profile': behavioral_profile,\n",
    "        'decision_heuristics': heuristics,\n",
    "        'raw_statistics': {\n",
    "            feature: {\n",
    "                'value': features[feature]['value'],\n",
    "                'zscore': features[feature]['zscore']\n",
    "            } for feature in RAW_FEATURES\n",
    "        },\n",
    "        'size': summary['size'],\n",
    "        'percentage': summary['percentage']\n",
    "    }\n",
    "\n",
    "\n",
    "# Generate personas for all clusters\n",
    "personas = {}\n",
    "for cluster_id, summary in cluster_summaries.items():\n",
    "    personas[cluster_id] = generate_persona_description(summary)\n",
    "\n",
    "print(f\"Generated {len(personas)} personas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all persona descriptions\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "for cluster_id, persona in personas.items():\n",
    "    display(Markdown(persona['description_markdown']))\n",
    "    display(Markdown(\"---\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate Agent System Prompts\n",
    "\n",
    "Create the system prompts that will be used to instantiate Claude agents in Phase 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_agent_system_prompt(persona: dict) -> str:\n",
    "    \"\"\"\n",
    "    Generate a system prompt for Claude agent instantiation.\n",
    "    \"\"\"\n",
    "    stats = persona['raw_statistics']\n",
    "    \n",
    "    prompt = f'''You are simulating a customer from the \"{persona['persona_name']}\" behavioral segment.\n",
    "\n",
    "## Context\n",
    "- Brazilian e-commerce customer (Olist marketplace, 2016-2018)\n",
    "- This persona represents {persona['percentage']:.1f}% of the customer base ({persona['size']:,} customers)\n",
    "\n",
    "## Behavioral Profile\n",
    "- Purchase frequency: {stats['frequency']['value']:.1f} orders (average)\n",
    "- Average lifetime spend: R${stats['monetary_total']['value']:.0f}\n",
    "- Typical item price: R${stats['monetary_avg_item']['value']:.0f}\n",
    "- Basket size: {stats['avg_items_per_order']['value']:.1f} items per order\n",
    "- Payment: {stats['pct_credit_card']['value']*100:.0f}% credit card, {stats['avg_installments']['value']:.1f} installments avg\n",
    "- Category diversity: {stats['category_diversity']['value']:.1f} distinct categories\n",
    "- Satisfaction: {stats['is_positive_reviewer']['value']*100:.0f}% positive reviews\n",
    "- Shopping timing: {\"weekend-oriented\" if stats['is_weekend_shopper']['value'] > 0.5 else \"weekday-oriented\" if stats['is_weekend_shopper']['value'] < 0.2 else \"no strong preference\"}\n",
    "\n",
    "## Decision Heuristics\n",
    "{chr(10).join(\"- \" + h for h in persona['decision_heuristics'])}\n",
    "\n",
    "## Instructions\n",
    "When presented with product scenarios, purchasing decisions, or marketplace situations:\n",
    "\n",
    "1. Respond as this customer persona would, based on the behavioral profile above\n",
    "2. Your preferences should reflect:\n",
    "   - The economic constraints implied by your spending patterns\n",
    "   - The risk tolerance implied by your payment preferences\n",
    "   - The satisfaction threshold implied by your review behavior\n",
    "3. Stay in character throughout the conversation\n",
    "4. When making decisions, briefly explain your reasoning in a way consistent with your persona\n",
    "\n",
    "Do not break character or acknowledge that you are an AI simulating a customer.\n",
    "'''\n",
    "    \n",
    "    return prompt.strip()\n",
    "\n",
    "\n",
    "# Generate system prompts for all personas\n",
    "agent_prompts = {}\n",
    "for cluster_id, persona in personas.items():\n",
    "    agent_prompts[cluster_id] = generate_agent_system_prompt(persona)\n",
    "\n",
    "# Display example\n",
    "print(\"Example Agent System Prompt (Cluster 0):\")\n",
    "print(\"=\" * 60)\n",
    "print(agent_prompts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Personas and Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare export data\n",
    "export_data = {\n",
    "    'metadata': {\n",
    "        'n_clusters': len(personas),\n",
    "        'total_customers': int(cluster_counts.sum()),\n",
    "        'features_used': RAW_FEATURES,\n",
    "        'generated_from': 'notebooks/04_persona_profiling.ipynb'\n",
    "    },\n",
    "    'population_statistics': {\n",
    "        'mean': population_stats.loc['mean'].to_dict(),\n",
    "        'median': population_stats.loc['median'].to_dict(),\n",
    "        'std': population_stats.loc['std'].to_dict()\n",
    "    },\n",
    "    'personas': {}\n",
    "}\n",
    "\n",
    "for cluster_id, persona in personas.items():\n",
    "    export_data['personas'][int(cluster_id)] = {\n",
    "        'persona_name': persona['persona_name'],\n",
    "        'size': persona['size'],\n",
    "        'percentage': persona['percentage'],\n",
    "        'behavioral_profile': persona['behavioral_profile'],\n",
    "        'decision_heuristics': persona['decision_heuristics'],\n",
    "        'raw_statistics': {\n",
    "            k: {'value': float(v['value']), 'zscore': float(v['zscore'])}\n",
    "            for k, v in persona['raw_statistics'].items()\n",
    "        },\n",
    "        'agent_system_prompt': agent_prompts[cluster_id]\n",
    "    }\n",
    "\n",
    "# Save to JSON\n",
    "with open(OUTPUT_DIR / 'personas.json', 'w') as f:\n",
    "    json.dump(export_data, f, indent=2)\n",
    "\n",
    "print(f\"Saved: {OUTPUT_DIR / 'personas.json'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cluster centroids (original scale)\n",
    "cluster_centroids.to_csv(OUTPUT_DIR / 'cluster_centroids.csv')\n",
    "print(f\"Saved: {OUTPUT_DIR / 'cluster_centroids.csv'}\")\n",
    "\n",
    "# Save cluster z-scores\n",
    "cluster_zscores.to_csv(OUTPUT_DIR / 'cluster_zscores.csv')\n",
    "print(f\"Saved: {OUTPUT_DIR / 'cluster_zscores.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save persona descriptions as markdown for easy reading\n",
    "with open(OUTPUT_DIR / 'persona_descriptions.md', 'w') as f:\n",
    "    f.write(\"# Customer Personas\\n\\n\")\n",
    "    f.write(f\"Generated from K-means clustering with {len(personas)} clusters.\\n\\n\")\n",
    "    f.write(\"---\\n\\n\")\n",
    "    \n",
    "    for cluster_id, persona in personas.items():\n",
    "        f.write(persona['description_markdown'])\n",
    "        f.write(\"\\n\\n---\\n\\n\")\n",
    "\n",
    "print(f\"Saved: {OUTPUT_DIR / 'persona_descriptions.md'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PERSONA PROFILING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nGenerated {len(personas)} customer personas:\")\n",
    "for cluster_id, persona in personas.items():\n",
    "    print(f\"  Cluster {cluster_id}: {persona['persona_name']} ({persona['size']:,} customers, {persona['percentage']:.1f}%)\")\n",
    "\n",
    "print(f\"\\nOutput files:\")\n",
    "print(f\"  1. personas.json - Complete persona data with agent prompts\")\n",
    "print(f\"  2. cluster_centroids.csv - Centroids in original scale\")\n",
    "print(f\"  3. cluster_zscores.csv - Cluster deviations from population\")\n",
    "print(f\"  4. persona_descriptions.md - Human-readable persona descriptions\")\n",
    "\n",
    "print(f\"\\nFigures:\")\n",
    "print(f\"  1. cluster_zscore_heatmap.png\")\n",
    "print(f\"  2. cluster_radar_charts.png\")\n",
    "\n",
    "print(f\"\\nNext Steps (Phase 3):\")\n",
    "print(f\"  1. Load personas.json\")\n",
    "print(f\"  2. Instantiate Claude agents using agent_system_prompt\")\n",
    "print(f\"  3. Design product scenarios for testing\")\n",
    "print(f\"  4. Run simulations and compare responses across personas\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
